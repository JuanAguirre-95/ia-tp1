{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion\n",
    "\n",
    "Dado un set de datos de accidentes automovilisticos se quieren utilizar tecnicas de Machine Learning para entrenar un modelo y poder predecir o clasificar la severidad de un accidente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tipo de problema\n",
    "\n",
    "Se desea entrenar el modelo para determinar la severidad de un accidente. La severidad se clasifica entre los valores 1 a 4, siendo 1 el menos severo y 4 el m√°s severo. Dado que debemos clasificar el set de datos con valores discretos lo mas conveniente seria utilizar modelos de clasificacion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables y caracteristicas\n",
    "\n",
    "Interpretar las variables del dataset y como pueden servirnos o no para la estimacion. Por que elegimos las columnas, que nuevas columnas podemos crear a partir de las que tenemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocesamiento del set de datos\n",
    "\n",
    "En este paso se determina el estado del dataset, que datos nos sirven y que se puede mejorar para que el entrenamiento sea satisfactorio.\n",
    "\n",
    "Ver tp1_dataset_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 933236 entries, 0 to 933235\n",
      "Columns: 176 entries, index to Sunrise_Sunset_Night\n",
      "dtypes: bool(13), float64(9), int64(4), timedelta64[ns](1), uint8(149)\n",
      "memory usage: 243.9 MB\n"
     ]
    }
   ],
   "source": [
    "#%store -r dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_feather(\"dataframe\")\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Time_Elapsed\"] = dataset[\"Time_Elapsed\"].astype(np.timedelta64) / np.timedelta64(1, 'h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de prediccion a aplicar\n",
    "\n",
    "Aca entraria una breve explicacion de que modelos vamos a usar y el por que\n",
    "\n",
    "* Formalizar tecnica de seleccion de datos\n",
    "* Evaluar modelos usados segun resultado obtenido\n",
    "* Comentar ventajas y desventajas de los modelos elegidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 1: SGD\n",
    "\n",
    "TODO: Breve explicacion de por que elegimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = dataset #features\n",
    "y = dataset[\"Severity\"] #target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y)\n",
    "est = make_pipeline(MinMaxScaler(), SGDClassifier(average=10))\n",
    "est.fit(X_train, Y_train)\n",
    "print(\"fit done\")\n",
    "y_pred = est.predict(X_test)\n",
    "score = metrics.accuracy_score(Y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96994972332829"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel(\"Valores para K\")\n",
    "plt.ylabel(\"Resultado de accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2: Clasificador KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Starting...\n",
      "Scaling done\n",
      "Knn Starting... 1\n",
      "Knn with k = 1 done\n"
     ]
    }
   ],
   "source": [
    "y = dataset[\"Severity\"] #target, se selecciona antes de escalar el dataset\n",
    "\n",
    "print(\"Scaling Starting...\")\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(dataset)\n",
    "print(\"Scaling done\")\n",
    "X = scaled #features\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y)\n",
    "\n",
    "k_range = range(1,21)\n",
    "#k_range = [20]\n",
    "scores = {}\n",
    "scores_list = []\n",
    "\n",
    "\n",
    "for k in k_range: #Automaticamente testeamos el modelo para k entre 1 y 25, y nos guardamos el accuracy de cada uno\n",
    "    print(\"Knn Starting...\",k)\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train,Y_train)\n",
    "    print(f\"Knn with k = {k} done\")\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(\"Pred done\")\n",
    "    #scores[k] = metrics.accuracy_score(Y_test, y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(Y_test, y_pred))\n",
    "    print(k, scores[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel(\"Valores para K\")\n",
    "plt.ylabel(\"Resultado de accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 3: Clasificador MLP (Multi-layered Perceptron)\n",
    "\n",
    "TODO: Armar una breve explicacion del por que lo elegimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentacion de los resultados obtenidos\n",
    "\n",
    "Aca mostrar resultados de las predicciones, graficos o lo que sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
